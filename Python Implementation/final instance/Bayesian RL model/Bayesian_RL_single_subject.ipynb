{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian RL Single Subject\n",
    "\n",
    "Before establishing an ierarchical model, first consider a Bayes RL model per subject.\n",
    "\n",
    "\n",
    "##### References:\n",
    "\n",
    "- (Bayes RL in PyMC3)(https://github.com/ricardoV94/stats/blob/master/modelling/RL_PyMC.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot -------------------------------------------------------------------------------------------*\n",
    "def plot_data(actions, rewards, Qs):\n",
    "    \n",
    "    plt.figure(figsize=(20,3))\n",
    "    x = np.arange(len(actions))\n",
    "\n",
    "    plt.plot(x, Qs[:, 0] - .5 + 0, c='C0', lw=3, alpha=.3)\n",
    "    plt.plot(x, Qs[:, 1] - .5 + 1, c='C1', lw=3, alpha=.3)\n",
    "\n",
    "    s = 50\n",
    "    lw = 2\n",
    "\n",
    "    cond = (actions == 0) & (rewards == 0)\n",
    "    plt.scatter(x[cond], actions[cond], s=s, c='None', ec='C0', lw=lw)\n",
    "\n",
    "    cond = (actions == 0) & (rewards == 1)\n",
    "    plt.scatter(x[cond], actions[cond], s=s, c='C0', ec='C0', lw=lw)\n",
    "\n",
    "    cond = (actions == 1) & (rewards == 0)\n",
    "    plt.scatter(x[cond], actions[cond], s=s, c='None', ec='C1', lw=lw)\n",
    "\n",
    "    cond = (actions == 1) & (rewards == 1)\n",
    "    plt.scatter(x[cond], actions[cond], s=s, c='C1', ec='C1', lw=lw)\n",
    "\n",
    "    plt.scatter(0, 20, c='k', s=s, lw=lw, label='Reward')\n",
    "    plt.scatter(0, 20, c='w', ec='k', s=s, lw=lw, label='No reward')\n",
    "    plt.plot([0,1], [20, 20], c='k', lw=3, alpha=.3, label='Qvalue (centered)')\n",
    "\n",
    "\n",
    "    plt.yticks([0,1], ['left', 'right'])\n",
    "    plt.ylim(-1, 2)\n",
    "\n",
    "    plt.ylabel('action')\n",
    "    plt.xlabel('trial')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    order = (1,2,0)\n",
    "    handles = [handles[idx] for idx in order]\n",
    "    labels = [labels[idx] for idx in order]\n",
    "\n",
    "    plt.legend(handles, labels, fontsize=12, loc=(1.01, .27))\n",
    "    plt.tight_layout()\n",
    "# plot -------------------------------------------------------------------------------------------*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# generate artificial data -----------------------------------------------------------------------*\n",
    "def generate_data(alpha, beta, n=100, p_r=[.4, .6]):\n",
    "    actions = np.zeros(n, dtype=np.int)\n",
    "    rewards = np.zeros(n, dtype=np.int)\n",
    "    Qs = np.zeros((n, 2))\n",
    "\n",
    "    # Initialize Q table\n",
    "    Q = np.array([.5, .5])\n",
    "    for i in range(n):\n",
    "        # Apply the Softmax transformation\n",
    "        exp_Q = np.exp(beta*Q)\n",
    "        prob_a = exp_Q / np.sum(exp_Q)\n",
    "\n",
    "        # Simulate choice and reward\n",
    "        a = np.random.choice([0, 1], p=prob_a)\n",
    "        r = np.random.rand() < p_r[a]\n",
    "\n",
    "        # Update Q table\n",
    "        Q[a] = Q[a] + alpha * (r - Q[a])\n",
    "\n",
    "        # Store values\n",
    "        actions[i] = a\n",
    "        rewards[i] = r\n",
    "        Qs[i] = Q.copy()\n",
    "\n",
    "    return actions, rewards, Qs\n",
    "# generate artificial data -----------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
