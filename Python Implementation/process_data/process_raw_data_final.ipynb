{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Raw Files\n",
    "\n",
    "This Notebook provides the code to process the raw _.txt_ files collected by the Psytoolkit Experiments.\n",
    "\n",
    "Experiments:\n",
    " - Navon\n",
    " - Fitts\n",
    " - N-Back\n",
    " - WCST\n",
    " - Corsi Block Span\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "```\n",
    "Author: Zach Wolpe \n",
    "Email:  zachcolinwolpe@gmail.com\n",
    "date:   05 July 2021\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_processing:\n",
    "    \"\"\"\n",
    "    Input:  path to data \n",
    "    Return: tools too write pandas dataframes of data to a specified location\n",
    "    \"\"\"\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path          = path_to_data\n",
    "        self.mapping       = pd.read_csv(self.path + '/data.csv', index_col=False)\n",
    "        self.data_times    = pd.read_csv(self.path + '/data_times.csv', index_col=False)\n",
    "        self.participants  = self.mapping['participant'].tolist()\n",
    "        self.parti_code    = self.mapping['participant_code:1'].tolist()\n",
    "        self.n             = self.mapping.shape[0]\n",
    "        self.wcst_paths    = [self.path  + wp for wp in self.mapping['wcst_task:1'].tolist()]\n",
    "        self.nback_paths   = [self.path  + wp for wp in self.mapping['n_back_task:1'].tolist()]\n",
    "        self.corsi_paths   = [self.path  + wp for wp in self.mapping['corsi_block_span_task:1'].tolist()]\n",
    "        self.fitts_paths   = [self.path  + wp for wp in self.mapping['fitts_law:1'].tolist()]\n",
    "        self.navon_paths   = [self.path  + wp for wp in self.mapping['navon_task:1'].tolist()]\n",
    "        self.wcst_data     = None\n",
    "        self.nback_data    = None\n",
    "        self.corsi_data    = None\n",
    "        self.fitts_data    = None\n",
    "        self.navon_data    = None\n",
    "\n",
    "    def create_wcst_data(self):\n",
    "        message = \"\"\"\n",
    "\n",
    "        ------------------------------------------------------------------\n",
    "                                WCST data created\n",
    "        ------------------------------------------------------------------\n",
    "\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        df = pd.DataFrame()\n",
    "        for p in range(self.n):\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            pc = self.parti_code[p]\n",
    "            pt = self.participants[p]\n",
    "\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            f = open(self.wcst_paths[p], 'r')\n",
    "            for l in f.readlines():\n",
    "                st  = l.split(' ')\n",
    "                crd = re.split(r'(\\d+)', st[5]) \n",
    "                dt  = {\n",
    "                    'participant':            pc,\n",
    "                    'participant_code':       pt,\n",
    "                    'card_no':                st[0],\n",
    "                    'correct_card':           st[1],\n",
    "                    'correct_persevering':    st[2],\n",
    "                    'seq_no':                 st[3],\n",
    "                    'rule':                   st[4],\n",
    "                    'card_shape':             crd[0],\n",
    "                    'card_number':            crd[1],\n",
    "                    'card_colour':            crd[2],\n",
    "                    'reaction_time_ms':       st[6],\n",
    "                    'status':                 st[7],\n",
    "                    'card_selected':          st[8],\n",
    "                    'error':                  st[9],\n",
    "                    'perseverance_error':     st[10],\n",
    "                    'not_perseverance_error': st[11].split('\\n')[0],\n",
    "                }\n",
    "                df = df.append(dt, ignore_index=True)[dt.keys()]\n",
    "        f.close()\n",
    "        self.wcst_data = df\n",
    "\n",
    "\n",
    "    def create_navon_data(self):\n",
    "        message = \"\"\"\n",
    "\n",
    "        ------------------------------------------------------------------\n",
    "                                Navon data created\n",
    "        ------------------------------------------------------------------\n",
    "\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        df = pd.DataFrame()\n",
    "        for p in range(self.n):\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            pc = self.parti_code[p]\n",
    "            pt = self.participants[p]\n",
    "\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            f = open(self.navon_paths[p], 'r')\n",
    "            for l in f.readlines():\n",
    "                st  = l.split(' ')\n",
    "                dt  = {\n",
    "                    'participant':            pc,\n",
    "                    'participant_code':       pt,\n",
    "                    'large_letter':           st[0][0],\n",
    "                    'small_letter':           st[0][0],\n",
    "                    'level_of_target':        st[1],\n",
    "                    'level_of_target_n':      st[2],\n",
    "                    'status':                 st[3],\n",
    "                    'reaction_time_ms':       st[4].split('\\n')[0],\n",
    "                }\n",
    "                df = df.append(dt, ignore_index=True)[dt.keys()]\n",
    "        f.close()\n",
    "        self.navon_data = df\n",
    "\n",
    "\n",
    "    def create_nback_data(self):\n",
    "        message = \"\"\"\n",
    "\n",
    "        ------------------------------------------------------------------\n",
    "                                N back data created\n",
    "        ------------------------------------------------------------------\n",
    "\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        df = pd.DataFrame()\n",
    "        for p in range(self.n):\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            pc = self.parti_code[p]\n",
    "            pt = self.participants[p]\n",
    "\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            f = open(self.nback_paths[p], 'r')\n",
    "            for l in f.readlines():\n",
    "                st  = l.split(' ')\n",
    "                dt  = {\n",
    "                    'participant':              pc,\n",
    "                    'participant_code':         pt,\n",
    "                    'block_number':             st[0],\n",
    "                    'score':                    st[1],\n",
    "                    'status':                   st[2],\n",
    "                    'miss':                     st[3],\n",
    "                    'false_alarm':              st[4],\n",
    "                    'reaction_time_ms':         st[5],\n",
    "                    'match':                    st[6],\n",
    "                    'stimuli':                  st[7],\n",
    "                    'stimuli_n_1':              st[8],\n",
    "                    'stimuli_n_2':              st[9].split('\\n')[0],\n",
    "                }\n",
    "                df = df.append(dt, ignore_index=True)[dt.keys()]\n",
    "        f.close()\n",
    "        self.nback_data = df\n",
    "\n",
    "\n",
    "    def create_corsi_data(self):\n",
    "        message = \"\"\"\n",
    "\n",
    "        ------------------------------------------------------------------\n",
    "                                Corsi data created\n",
    "        ------------------------------------------------------------------\n",
    "\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        df = pd.DataFrame()\n",
    "        for p in range(self.n):\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            pc = self.parti_code[p]\n",
    "            pt = self.participants[p]\n",
    "\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            f = open(self.corsi_paths[p], 'r')\n",
    "            for l in f.readlines():\n",
    "                st  = l.split(' ')\n",
    "                dt  = {\n",
    "                    'participant':              pc,\n",
    "                    'participant_code':         pt,\n",
    "                    'highest_span':             st[0],\n",
    "                    'n_items':                  st[1],\n",
    "                    'status':                   st[2].split('\\n')[0],\n",
    "                }\n",
    "                df = df.append(dt, ignore_index=True)[dt.keys()]\n",
    "        f.close()\n",
    "        self.corsi_data = df\n",
    "\n",
    "\n",
    "\n",
    "    def create_fitts_data(self):\n",
    "        message = \"\"\"\n",
    "\n",
    "        ------------------------------------------------------------------\n",
    "                                Fitts data created\n",
    "        ------------------------------------------------------------------\n",
    "\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        df = pd.DataFrame()\n",
    "        for p in range(self.n):\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            pc = self.parti_code[p]\n",
    "            pt = self.participants[p]\n",
    "\n",
    "            # _____ FOR EACH PARTICIPANT -----x\n",
    "            f = open(self.fitts_paths[p], 'r')\n",
    "            for l in f.readlines():\n",
    "                st  = l.split(' ')\n",
    "                dt  = {\n",
    "                    'participant':              pc,\n",
    "                    'participant_code':         pt,\n",
    "                    'x_loc':                    st[0],\n",
    "                    'y_loc':                    st[1],\n",
    "                    'size':                     st[2],\n",
    "                    'distance':                 st[3],\n",
    "                    'fitts_prediction':         st[4],\n",
    "                    'reaction_time_ms':         st[5],\n",
    "                    'status':                   st[6].split('\\n')[0],\n",
    "                }\n",
    "                df = df.append(dt, ignore_index=True)[dt.keys()]\n",
    "        f.close()\n",
    "        self.fitts_data = df\n",
    "\n",
    "\n",
    "\n",
    "    def convert_data_to_int(self):\n",
    "        \"\"\"Change the schema of the dataframes to include integers\"\"\"\n",
    "        # converter function\n",
    "        def str_to_int(df, columns):\n",
    "            for c in columns: df[c] = df[c].astype(int)\n",
    "            return(df)\n",
    "\n",
    "        # convert schemas\n",
    "        self.fitts_data = str_to_int(self.fitts_data, \n",
    "        ['x_loc', 'y_loc', 'size', 'distance', 'fitts_prediction', 'reaction_time_ms', 'status'])\n",
    "\n",
    "        self.corsi_data = str_to_int(self.corsi_data, ['highest_span', 'n_items', 'status'])\n",
    "\n",
    "        self.nback_data = str_to_int(self.nback_data, \n",
    "        ['block_number', 'score', 'status','miss', 'false_alarm', 'reaction_time_ms', 'match', \n",
    "        'stimuli','stimuli_n_1', 'stimuli_n_2'])\n",
    "\n",
    "        self.wcst_data = str_to_int(self.wcst_data, \n",
    "        ['card_no', 'correct_card', 'correct_persevering', 'seq_no', 'card_number', 'reaction_time_ms', 'status', \n",
    "        'card_selected', 'error', 'perseverance_error', 'not_perseverance_error'])\n",
    "\n",
    "        self.navon_data = str_to_int(self.navon_data, ['level_of_target_n', 'status', 'reaction_time_ms'])\n",
    "        message=\"\"\"\n",
    "        ------------------------------------------------------------------\n",
    "        Schemas Converted!\n",
    "        ------------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "\n",
    "\n",
    "    def write_to_pickle(self, path):\n",
    "        \"\"\"Write the data to pickle files\"\"\"\n",
    "        try: os.mkdir(path)\n",
    "        except: None\n",
    "\n",
    "        self.fitts_data.to_pickle(path + 'fitts_data.pkl')\n",
    "        self.wcst_data.to_pickle(path  + 'wcst_data.pkl')\n",
    "        self.nback_data.to_pickle(path + 'nback_data.pkl')\n",
    "        self.corsi_data.to_pickle(path + 'corsi_data.pkl')\n",
    "        self.navon_data.to_pickle(path + 'navon_data.pkl')\n",
    "        message=\"\"\"\n",
    "        ------------------------------------------------------------------\n",
    "        Dataframes successfully written to path {}!\n",
    "        ------------------------------------------------------------------\n",
    "        \"\"\".format(path)\n",
    "        print(message)\n",
    "\n",
    "\n",
    "    def read_from_pickle(self, path):\n",
    "        \"\"\"Read the data to pickle files\"\"\"\n",
    "        self.fitts_data = pd.read_pickle(path + 'fitts_data.pkl')\n",
    "        self.wcst_data  = pd.read_pickle(path + 'wcst_data.pkl')\n",
    "        self.nback_data = pd.read_pickle(path + 'nback_data.pkl')\n",
    "        self.corsi_data = pd.read_pickle(path + 'corsi_data.pkl')\n",
    "        self.navon_data = pd.read_pickle(path + 'navon_data.pkl')\n",
    "        message=\"\"\"\n",
    "        ------------------------------------------------------------------\n",
    "        Dataframes:\n",
    "\n",
    "            - fitts_data\n",
    "            - wcst_data\n",
    "            - nback_data\n",
    "            - corsi_data\n",
    "            - navon_data\n",
    "\n",
    "        Successfully read from path: \\'{}\\'!\n",
    "        ------------------------------------------------------------------\n",
    "        \"\"\".format(path)\n",
    "        print(message)\n",
    "\n",
    "\n",
    "    def write_class_to_pickle(self, path):\n",
    "        \"\"\"serialize object to pickle object\"\"\"\n",
    "\n",
    "        #save it\n",
    "        filename = path + 'batch_processing_object.pkl'\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(bp, file) \n",
    "\n",
    "        # #load it\n",
    "        # with open(filename, 'rb') as file2:\n",
    "        #     bp = pickle.load(file2)\n",
    "        message=\"\"\"\n",
    "        ------------------------------------------------------------------\n",
    "        Object successfully written to path: \\'{}\\'!\n",
    "\n",
    "        To retrieve run:\n",
    "            with open(\\'{}\\', 'rb') as file2:\n",
    "                bp = pickle.load(file2)\n",
    "        ------------------------------------------------------------------\n",
    "        \"\"\".format(filename, filename)\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                WCST data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Navon data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                N back data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Corsi data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Fitts data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Schemas Converted!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes successfully written to path ../data/data_samples_pandas/!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes:\n",
      "\n",
      "            - fitts_data\n",
      "            - wcst_data\n",
      "            - nback_data\n",
      "            - corsi_data\n",
      "            - navon_data\n",
      "\n",
      "        Successfully read from path: '../data/data_samples_pandas/'!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Object successfully written to path: '../data/data_samples_pandas/batch_processing_object.pkl'!\n",
      "\n",
      "        To retrieve run:\n",
      "            with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
      "                bp = pickle.load(file2)\n",
      "        ------------------------------------------------------------------\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "path  = '../data/data_sample/'\n",
    "path2 = '../data/data_samples_pandas/'\n",
    "bp   = batch_processing(path)\n",
    "\n",
    "\n",
    "bp.create_wcst_data()\n",
    "bp.create_navon_data()\n",
    "bp.create_nback_data()\n",
    "bp.create_corsi_data()\n",
    "bp.create_fitts_data()\n",
    "bp.convert_data_to_int()\n",
    "bp.write_to_pickle(path2)\n",
    "bp.read_from_pickle(path2)\n",
    "bp.write_class_to_pickle(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
    "    bp = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.batch_processing"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('dynocog': conda)",
   "name": "python388jvsc74a57bd00bdb1145a6394107ddd55d824c4d0e411e79cd19a6286b1018600d724ae6ee81"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
