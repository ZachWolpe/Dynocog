{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('dynocog': conda)"
  },
  "interpreter": {
   "hash": "0bdb1145a6394107ddd55d824c4d0e411e79cd19a6286b1018600d724ae6ee81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# N Back Task\n",
    "\n",
    "Theoretical description of the modelling framework: N-Back task.\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "\n",
    "## Define Statespace\n",
    "\n",
    "Define also possible variables in the model, formalising the task as a probabilistic mathematical construct.\n",
    "\n",
    "----------\n",
    "\n",
    "## Action Space: Output Space\n",
    "\n",
    "The $\\mathcal{A}: Action \\; Space$ is the number of possible actions an agent can take. The action sequence in the *N-Back* task can be encoded in binary:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    \\mathcal{A} := \n",
    "    \\begin{cases}\n",
    "      0, & \\text{if}\\  \\text{agent} \\; \\mathcal{a} \\; \\text{signals an nback match} \\\\\n",
    "      1, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "----------\n",
    "\n",
    "## State Space: Input Space\n",
    "\n",
    "The $\\mathcal{S}: State \\; Space$ represents the encoding of the environment. It should be rich enough to capture the complexity of the problem, but not so rich as to totally defeat the possibility of learning a functional approximation given the available data,\n",
    "\n",
    "In our task, there are $15$ unique letters, encoded:\n",
    "\n",
    "\n",
    "$$\\{A, B, C, D, ..., O\\}  \\; \\rightarrow \\; \\{1,2,3,...,15\\}$$\n",
    "\n",
    "\n",
    "#### Covariates\n",
    "\n",
    "With this encoding, there are $4$ covariates:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\phi_0 &:=& \\text{current card} \\\\\n",
    "\\phi_1 &:=& \\text{1 card back} \\\\\n",
    "\\phi_2 &:=& \\text{2 cards back} \\\\\n",
    "\\phi_3 &:=& \\text{3 cards back} \\\\\n",
    "\\tau &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\\phi_j \\in [1:15]$$\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "## Reduced Space\n",
    "\n",
    "This may provide a level of complexity that is undesirable & adds little explanatory benefits. Instead we encode the $trailing \\; 3$ cards in binary, where:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    phi_j := \n",
    "    \\begin{cases}\n",
    "      1, & \\text{if card }\\ i  \\text{ equals the current card.} \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$for \\ j \\in [1,2,3]$ - note it is also no longer neccessary to keep track of the current cards value. By using this reduced encoding we are assuming individual's will perform similarly if the same experimental instance was applied with different cards - which is a plausible assumption.\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "## Final State Space\n",
    "\n",
    "The reduced may lack some necessary complexity, suppose:\n",
    "\n",
    "\n",
    "> The previous cards do not match the current card, but do match each other.\n",
    "\n",
    "This could easily confuse the candidate, however under the reduced form representation there is no way for the model to discern this from the case where all cards are different. It is still not necessary to capture unique letter types, so to add this capability we simply need $4$ encoding possibilities:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    \\phi_j := \n",
    "    \\begin{cases}\n",
    "      \\mathcal{a}, & \\text{if card }\\ j  \\text{ matches the current card.} \\\\\n",
    "      \\mathcal{b}, & \\text{the first unique card} \\\\\n",
    "      \\mathcal{c}, & \\text{the second unique card} \\\\\n",
    "      \\mathcal{d}, & \\text{the third unique card} \n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "## Final Covariates \n",
    "\n",
    "Leveraging this reduced form, our final model has $4$ explantory variables:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\phi_1 &:=& \\text{1 card back} \\\\\n",
    "\\phi_2 &:=& \\text{2 cards back} \\\\\n",
    "\\phi_3 &:=& \\text{3 cards back} \\\\\n",
    "\\tau &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "## Choice Probability\n",
    "\n",
    "Theres covariates need to capture the probability of taking an action (signalling an $n-back$ match). The data is encoded in the design matrix $X$, with columns:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\{x_1, x_2, x_3\\} &  \\rightarrow & \\{\\mathcal{a,b,c,d}\\} \\\\\n",
    "x_4     &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### Interaction Terms\n",
    "\n",
    "One might expect interaction between terms at certain sequence pairs may confuse candidates. $\\{\\phi_4, \\phi_5, \\phi_6\\}$ are added as interaction terms.\n",
    "\n",
    "\n",
    "#### Choice Probability\n",
    "\n",
    "Our choice is binary, thus we can denote the probability of signalling a match $P[a=1]$ as a, letting $p \\in [0,1]$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "  ZX                &=& \\phi_0 + \\phi_1 x_1 + \\phi_2 x_2 + \\phi_3 x_3 + \n",
    "                        \\phi_4 x_1 x_2 + \\phi_5 x_1 x_3 + \\phi_6 x_2 x_3 + \\tau x_4 \\\\\n",
    "  log\\frac{p}{1-p}  &=& ZX \\\\\n",
    "  \\frac{p}{1-p}     &=& exp\\{ ZX \\} \\\\\n",
    "  p                 &=& \\frac{exp\\{ ZX \\}}{1 + exp\\{ ZX \\}} \\\\\n",
    "  p                 &=& \\frac{1}{1 + exp\\{ -ZX \\}} \\\\\n",
    "  p                 &=& \\sigma(ZX) \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "This represents the model for a single individual. More flexible function approximates may be tested, but are probably not neccessary.\n",
    "\n",
    "**_Interaction terms should be added to the $ZX$ formulation._**\n",
    "\n",
    "\n",
    "---------- \n",
    "\n",
    "## Individual Models: Bayesian Model\n",
    "\n",
    "Each participant should have an individual model (unique parameters) that will be regularised in a Bayesian fashion. Thus each parameter needs to be index by:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "i &:=& \\text{participant i} \\\\\n",
    "t &:=& \\text{time t} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "## Additions\n",
    "\n",
    "A number of additions are to be added:\n",
    "- Bayesian hierarchical framework to regulate variation across individuals\n",
    "- Fitts law parameterisation\n",
    "- Corsi parameterisation\n",
    "- Navon parameterisation\n",
    "- WCST parameterisation (possibly)\n",
    "\n",
    "\n",
    "```\n",
    "author: Zach Wolpe\n",
    "email:  zachcolinwolpe@gmail.com\n",
    "date:   22 June 2021\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Final Draft: NBack\n",
    "\n",
    "Modelled as a Q learning instance:\n",
    "\n",
    "$$actions: a:=\\{\\}$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda activate dynocog\n",
    "# !conda init\n",
    "# !conda install pandas -y\n",
    "# !conda install -c pytorch pytorch -y\n",
    "# !conda install -c conda-forge numpyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---- load data module ----x\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import process_data.process_raw_data as prd\n",
    "from process_data.process_raw_data import batch_processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                WCST data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Navon data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                N back data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Corsi data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Fitts data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Schemas Converted!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes successfully written to path ../data/data_samples_pandas/!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes:\n",
      "\n",
      "            - fitts_data\n",
      "            - wcst_data\n",
      "            - nback_data\n",
      "            - corsi_data\n",
      "            - navon_data\n",
      "\n",
      "        Successfully read from path: '../data/data_samples_pandas/'!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Object successfully written to path: '../data/data_samples_pandas/batch_processing_object.pkl'!\n",
      "\n",
      "        To retrieve run:\n",
      "            with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
      "                bp = pickle.load(file2)\n",
      "        ------------------------------------------------------------------\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# ---- reprocess raw data ----x\n",
    "path  = '../data/data_sample/'\n",
    "path2 = '../data/data_samples_pandas/'\n",
    "bp    = prd.batch_processing(path)\n",
    "\n",
    "bp.create_wcst_data()\n",
    "bp.create_navon_data()\n",
    "bp.create_nback_data()\n",
    "bp.create_corsi_data()\n",
    "bp.create_fitts_data()\n",
    "bp.convert_data_to_int()\n",
    "bp.write_to_pickle(path2)\n",
    "bp.read_from_pickle(path2)\n",
    "bp.write_class_to_pickle(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['path', 'mapping', 'data_times', 'participants', 'parti_code', 'n', 'wcst_paths', 'nback_paths', 'corsi_paths', 'fitts_paths', 'navon_paths', 'wcst_data', 'nback_data', 'corsi_data', 'fitts_data', 'navon_data'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# ---- fetch data object ----x\n",
    "with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
    "    bp = pickle.load(file2)\n",
    "bp.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = bp.nback_data.loc[bp.nback_data.participant ==851366.0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   participant                            participant_code  block_number  \\\n",
       "0     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "1     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "2     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "3     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "4     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "\n",
       "   score  status  miss  false_alarm  reaction_time_ms  match  stimuli  \\\n",
       "0      1       0     1            0                 0      0     3000   \n",
       "1      2       0     1            0                 0      0     3000   \n",
       "2      3       0     1            0                 0      0     3000   \n",
       "3      4       1     0            0                 1      0     3000   \n",
       "4      5       0     0            0                 0      1      867   \n",
       "\n",
       "   stimuli_n_1  stimuli_n_2  \n",
       "0            1           14  \n",
       "1            2           13  \n",
       "2            3           10  \n",
       "3            1           13  \n",
       "4            2           12  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant</th>\n      <th>participant_code</th>\n      <th>block_number</th>\n      <th>score</th>\n      <th>status</th>\n      <th>miss</th>\n      <th>false_alarm</th>\n      <th>reaction_time_ms</th>\n      <th>match</th>\n      <th>stimuli</th>\n      <th>stimuli_n_1</th>\n      <th>stimuli_n_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>2</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>867</td>\n      <td>2</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}