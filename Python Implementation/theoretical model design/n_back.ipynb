{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00bdb1145a6394107ddd55d824c4d0e411e79cd19a6286b1018600d724ae6ee81",
   "display_name": "Python 3.8.8 64-bit ('dynocog': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# N Back Task\n",
    "\n",
    "Theoretical description of the modelling framework: N-Back task.\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "\n",
    "## Define Statespace\n",
    "\n",
    "Define also possible variables in the model, formalising the task as a probabilistic mathematical construct.\n",
    "\n",
    "----------\n",
    "\n",
    "## Action Space: Output Space\n",
    "\n",
    "The $\\mathcal{A}: Action \\; Space$ is the number of possible actions an agent can take. The action sequence in the *N-Back* task can be encoded in binary:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    \\mathcal{A} := \n",
    "    \\begin{cases}\n",
    "      0, & \\text{if}\\  \\text{agent} \\; \\mathcal{a} \\; \\text{signals an nback match} \\\\\n",
    "      1, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "----------\n",
    "\n",
    "## State Space: Input Space\n",
    "\n",
    "The $\\mathcal{S}: State \\; Space$ represents the encoding of the environment. It should be rich enough to capture the complexity of the problem, but not so rich as to totally defeat the possibility of learning a functional approximation given the available data,\n",
    "\n",
    "In our task, there are $15$ unique letters, encoded:\n",
    "\n",
    "\n",
    "$$\\{A, B, C, D, ..., O\\}  \\; \\rightarrow \\; \\{1,2,3,...,15\\}$$\n",
    "\n",
    "\n",
    "#### Covariates\n",
    "\n",
    "With this encoding, there are $4$ covariates:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\phi_0 &:=& \\text{current card} \\\\\n",
    "\\phi_1 &:=& \\text{1 card back} \\\\\n",
    "\\phi_2 &:=& \\text{2 cards back} \\\\\n",
    "\\phi_3 &:=& \\text{3 cards back} \\\\\n",
    "\\tau &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\\phi_j \\in [1:15]$$\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "## Reduced Space\n",
    "\n",
    "This may provide a level of complexity that is undesirable & adds little explanatory benefits. Instead we encode the $trailing \\; 3$ cards in binary, where:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    phi_j := \n",
    "    \\begin{cases}\n",
    "      1, & \\text{if card }\\ i  \\text{ equals the current card.} \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$for \\ j \\in [1,2,3]$ - note it is also no longer neccessary to keep track of the current cards value. By using this reduced encoding we are assuming individual's will perform similarly if the same experimental instance was applied with different cards - which is a plausible assumption.\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "----------\n",
    "## Final State Space\n",
    "\n",
    "The reduced may lack some necessary complexity, suppose:\n",
    "\n",
    "\n",
    "> The previous cards do not match the current card, but do match each other.\n",
    "\n",
    "This could easily confuse the candidate, however under the reduced form representation there is no way for the model to discern this from the case where all cards are different. It is still not necessary to capture unique letter types, so to add this capability we simply need $4$ encoding possibilities:\n",
    "\n",
    "$$: \n",
    "\\begin{equation}\n",
    "    \\phi_j := \n",
    "    \\begin{cases}\n",
    "      \\mathcal{a}, & \\text{if card }\\ j  \\text{ matches the current card.} \\\\\n",
    "      \\mathcal{b}, & \\text{the first unique card} \\\\\n",
    "      \\mathcal{c}, & \\text{the second unique card} \\\\\n",
    "      \\mathcal{d}, & \\text{the third unique card} \n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "## Final Covariates \n",
    "\n",
    "Leveraging this reduced form, our final model has $4$ explantory variables:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\phi_1 &:=& \\text{1 card back} \\\\\n",
    "\\phi_2 &:=& \\text{2 cards back} \\\\\n",
    "\\phi_3 &:=& \\text{3 cards back} \\\\\n",
    "\\tau &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "## Choice Probability\n",
    "\n",
    "Theres covariates need to capture the probability of taking an action (signalling an $n-back$ match). The data is encoded in the design matrix $X$, with columns:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "\\{x_1, x_2_, x_3\\} &  \\rightarrow & \\{\\mathcal{a,b,c,d}\\} \\\\\n",
    "x_4     &:=& \\text{number of occurances of the current card} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### Interaction Terms\n",
    "\n",
    "One might expect interaction between terms at certain sequence pairs may confuse candidates. $\\{\\phi_4, \\phi_5, \\phi_6\\}$ are added as interaction terms.\n",
    "\n",
    "\n",
    "#### Choice Probability\n",
    "\n",
    "Our choice is binary, thus we can denote the probability of signalling a match $P[a=1]$ as a, letting $p \\in [0,1]$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "  ZX                &=& \\phi_0 + \\phi_1 x_1 + \\phi_2 x_2 + \\phi_3 x_3 + \n",
    "                        \\phi_4 x_1 x_2 + \\phi_5 x_1 x_3 + \\phi_6 x_2 x_3 + \\tau x_4 \\\\\n",
    "  log\\frac{p}{1-p}  &=& ZX \\\\\n",
    "  \\frac{p}{1-p}     &=& exp\\{ ZX \\} \\\\\n",
    "  p                 &=& \\frac{exp\\{ ZX \\}}{1 + exp\\{ ZX \\}} \\\\\n",
    "  p                 &=& \\frac{1}{1 + exp\\{ -ZX \\}} \\\\\n",
    "  p                 &=& \\sigma(ZX) \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "This represents the model for a single individual. More flexible function approximates may be tested, but are probably not neccessary.\n",
    "\n",
    "**_Interaction terms should be added to the $ZX$ formulation._**\n",
    "\n",
    "\n",
    "---------- \n",
    "\n",
    "## Individual Models: Bayesian Model\n",
    "\n",
    "Each participant should have an individual model (unique parameters) that will be regularised in a Bayesian fashion. Thus each parameter needs to be index by:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "i &:=& \\text{participant i} \\\\\n",
    "t &:=& \\text{time t} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "## Additions\n",
    "\n",
    "A number of additions are to be added:\n",
    "- Bayesian hierarchical framework to regulate variation across individuals\n",
    "- Fitts law parameterisation\n",
    "- Corsi parameterisation\n",
    "- Navon parameterisation\n",
    "- WCST parameterisation (possibly)\n",
    "\n",
    "\n",
    "```\n",
    "author: Zach Wolpe\n",
    "email:  zachcolinwolpe@gmail.com\n",
    "date:   22 June 2021\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "\n",
    "\n",
    "## Optimal Behaviour\n",
    "\n",
    "#### Deterministic Task\n",
    "\n",
    "The task is deterministic thus programming the best possible behaviour is trivial:\n",
    "- Store the sequence of information\n",
    "- Trigger if matches\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "# Formalisation\n",
    "\n",
    "Here we provide a mathematical formalism to represent the _N-back_ task. The _optimal agent_ will assume the known correct probabilities, whilst the data can will be used to infer parameters that capture these probabilities - allowing us to measure the deviation from optimal performance across individuals.\n",
    "\n",
    "\n",
    "-------\n",
    "\n",
    "## State Space\n",
    "\n",
    "The _N Back_ task can be considered a dichotomous state space, with two mutually exclusive states representing whether or not the current stimuli (lekker) matches that of the stimuli _N_ steps prior. That is:\n",
    "\n",
    "\n",
    "$$State: S = \\{Y, N\\}$$\n",
    "\n",
    "Where: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " Y = \\text{Yes: there is a match} \\\\\n",
    " N = \\text{No: there is not a match} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Where a particular instance is denoted by the lowercase $y$ or $n$ respectively. Further, there is no desire to learn transition dynamics as the states are entirely independent.\n",
    "\n",
    "$$\\text{The function of the state space is only to constrain the action space, by conditioning the action space on the state space.}$$\n",
    "\n",
    "\n",
    "-----------\n",
    "## Action Space\n",
    "\n",
    "Each participant has independent parameters quantifying the probability of the possible actions. (Note: the individual parameters can later incorporate joint distributional information by incorporating Bayesian priors over all participants).\n",
    "\n",
    "The action space is dichotomous & defined as:\n",
    "\n",
    "\n",
    "- *C* - _*Correct*_:      accurately signaling whether or not there is a match.\n",
    "- *I* - _*Incorrect*_:    inaccurately signaling a match erroneously\n",
    "\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$Action \\ Space: \\{C, I\\}$$\n",
    "\n",
    "\n",
    "We can represent the likelikhood of taking a specific action as non-stationary probabilities (non-stationary as they change over the course of the task, thus indexed by time $t$). An individual probability should be learnt for each participant $p$:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_t^p(j) \\ \\ for \\ \\  j=\\{c, i\\}\n",
    "\\end{equation}\n",
    "\n",
    "That is:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_t^p(c) = \\text{probability of partipicpant $p$ takes the correct action at time $t$}\\\\\n",
    "\\delta_t^p(i) = \\text{probability of partipicpant $p$ takes the incorrect action at time $t$}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Dichotomous Actions\n",
    "\n",
    "Because the actions are binary, we can simply assume:\n",
    "\n",
    "$$\\delta_t^p(c) = 1 - \\delta_t^p(i)$$\n",
    "\n",
    "Thus only need to model:\n",
    "\n",
    "$$\\delta_t^p(a)$$\n",
    "\n",
    "Where $a$ is the dichotomosu action taken (signal a match, or do not signal a match).\n",
    "\n",
    "#### Dependence on State\n",
    "\n",
    "The action space is conditioned on the state $s$. Inituitively, one can expect the probability of taking the correct action to be higher when the correct action is to do nothing then when the correct action is to signal a match. \n",
    "\n",
    "Therefore the parameters ought to capture this dependence on state:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_t^p(a|s) \\ \\ \\ \\ where \\ s=:\\{y,n\\}\n",
    "\\end{equation}\n",
    "\n",
    "Thus we arrive at:\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta_t^p(a|s) = \\text{probability of partipicpant $p$ takes the correct action $c$ at time $t$, given state $s$}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Transition probability? - Temporal Dependence\n",
    "\n",
    "In this particular task, we cane expect the samples to be fairly independent. We know there are no transitition dynamics as there is no dependence between states. \n",
    "\n",
    "_*however, is there a need to capture the effects of time? Or does the parameter updating process account for this?*_\n",
    "\n",
    "\n",
    "## Parameter Updating\n",
    "\n",
    "\n",
    "------ \n",
    "\n",
    "## Optimal model\n",
    "The optimal model simply results in \n",
    "\n",
    "$$\\delta_t^p(a|s) = 1$$\n",
    "\n",
    "_Our primary interest is to assess how different individuals deviate from this optimality by learning the probabilities as a parameter across individuals._\n",
    "\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "# Instantiate Model\n",
    "\n",
    "We define the model class with learnable parameters:\n",
    "\n",
    "$$\\delta^p(a|s) = 1 \\ \\ for \\ a=\\{0,1\\}, \\ \\ s=\\{0,1\\}$$\n",
    "\n",
    "$t$ is dropped as it does not index a parameter, but rather indicate the parameter value at a given time period $t$ (during training).\n",
    "\n",
    "Recall that $\\delta^p(a|s)$ denotes:\n",
    "- $\\delta^p(a|s)$: probabilty of action $a$ given state $s$\n",
    "- $a:\\{signal, no-signal\\}$: whether or not the participant signals the event\n",
    "- $s:\\{match, no-match\\}$: whether or not there is actually a match\n",
    "\n",
    "The conditional is provided as we expect the probabilites to differ significantly between states.\n",
    "\n",
    "## Without Data \n",
    "\n",
    "Before training the parameters, we can specify them to be some arbitrary value, the optimal value being:\n",
    "\n",
    "- $\\delta^p(1|1) = 1$\n",
    "- $\\delta^p(0|1) = 0$\n",
    "- $\\delta^p(1|0) = 0$\n",
    "- $\\delta^p(0|0) = 1$\n",
    "\n",
    "## Fitting Data\n",
    "\n",
    "We are able to fit the data to these parameters by best \n",
    "\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "\n",
    "- Temporal Dependence in the simplies case (N Back task)\n",
    "- Extend Temporal dependence into the more complicated models (Corsi Block Span etc)\n",
    "- NBack == above\n",
    "- Navon == almost identical to this model\n",
    "- Corsi == greater temporal dependence\n",
    "- Fitts == known formula, how to handle this??? How to quantify the deviation? Capture the variation overtime?\n",
    "- WCST  == Q-learning multi-arm bandit task \n",
    "\n",
    "\n",
    "## RL - J.Shock\n",
    "\n",
    "RL is generally the _*optimization technique*_ - requiring *many, many* runs. In our instances, RL is not the optimisation technique, but rather the framework? How would we optimize this? Over many samples (Bayes)?\n",
    "\n",
    "## Time Series models\n",
    "## Gausian Processes (Cool)\n",
    "## Markov Models\n",
    "\n",
    "# Objective\n",
    "## 1. Specify statistical framework to represent the task\n",
    "\n",
    "    - *Action* probabilities\n",
    "    - *State* possible \n",
    "    - *Transition* probabilities\n",
    "    - *Hierarchical* structure\n",
    "\n",
    "    - timing parameter\n",
    "    - transition dynamics (dependency on sequence)\n",
    "        - additional variable caputuring history (repeated letters)\n",
    "        - state space: encoding of last _k_ letters (k=4) \n",
    "            --> binary encoding of current letter or not\n",
    "            --> encoding current & previous letter\n",
    "\n",
    "\n",
    "# Bayesian Inference\n",
    "- assumed DGP per participant _p_ (distributional assumptions)\n",
    "- each participant has a unique parameter/s that draws from the (common) distribution\n",
    "- Bayes regularises via the assumed prior\n",
    "\n",
    "- different distribution \n",
    "\n",
    "## Hidden Markov Models\n",
    "\n",
    "True model: underlying process\n",
    "Participant: behaviour \n",
    "\n",
    "Statistics: model is a assumption \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda activate dynocog\n",
    "# !conda init\n",
    "# !conda install pandas -y\n",
    "# !conda install -c pytorch pytorch -y\n",
    "# !conda install -c conda-forge numpyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---- load data module ----x\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import process_data.process_raw_data as prd\n",
    "from process_data.process_raw_data import batch_processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                WCST data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Navon data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                N back data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Corsi data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "                                Fitts data created\n",
      "        ------------------------------------------------------------------\n",
      "\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Schemas Converted!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes successfully written to path ../data/data_samples_pandas/!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Dataframes:\n",
      "\n",
      "            - fitts_data\n",
      "            - wcst_data\n",
      "            - nback_data\n",
      "            - corsi_data\n",
      "            - navon_data\n",
      "\n",
      "        Successfully read from path: '../data/data_samples_pandas/'!\n",
      "        ------------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        ------------------------------------------------------------------\n",
      "        Object successfully written to path: '../data/data_samples_pandas/batch_processing_object.pkl'!\n",
      "\n",
      "        To retrieve run:\n",
      "            with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
      "                bp = pickle.load(file2)\n",
      "        ------------------------------------------------------------------\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# ---- reprocess raw data ----x\n",
    "path  = '../data/data_sample/'\n",
    "path2 = '../data/data_samples_pandas/'\n",
    "bp    = prd.batch_processing(path)\n",
    "\n",
    "bp.create_wcst_data()\n",
    "bp.create_navon_data()\n",
    "bp.create_nback_data()\n",
    "bp.create_corsi_data()\n",
    "bp.create_fitts_data()\n",
    "bp.convert_data_to_int()\n",
    "bp.write_to_pickle(path2)\n",
    "bp.read_from_pickle(path2)\n",
    "bp.write_class_to_pickle(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['path', 'mapping', 'data_times', 'participants', 'parti_code', 'n', 'wcst_paths', 'nback_paths', 'corsi_paths', 'fitts_paths', 'navon_paths', 'wcst_data', 'nback_data', 'corsi_data', 'fitts_data', 'navon_data'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# ---- fetch data object ----x\n",
    "with open('../data/data_samples_pandas/batch_processing_object.pkl', 'rb') as file2:\n",
    "    bp = pickle.load(file2)\n",
    "bp.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = bp.nback_data.loc[bp.nback_data.participant ==851366.0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   participant                            participant_code  block_number  \\\n",
       "0     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "1     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "2     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "3     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "4     851366.0  s.32ff642a-efe0-436f-8075-fa703d677fed.txt             1   \n",
       "\n",
       "   score  status  miss  false_alarm  reaction_time_ms  match  stimuli  \\\n",
       "0      1       0     1            0                 0      0     3000   \n",
       "1      2       0     1            0                 0      0     3000   \n",
       "2      3       0     1            0                 0      0     3000   \n",
       "3      4       1     0            0                 1      0     3000   \n",
       "4      5       0     0            0                 0      1      867   \n",
       "\n",
       "   stimuli_n_1  stimuli_n_2  \n",
       "0            1           14  \n",
       "1            2           13  \n",
       "2            3           10  \n",
       "3            1           13  \n",
       "4            2           12  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant</th>\n      <th>participant_code</th>\n      <th>block_number</th>\n      <th>score</th>\n      <th>status</th>\n      <th>miss</th>\n      <th>false_alarm</th>\n      <th>reaction_time_ms</th>\n      <th>match</th>\n      <th>stimuli</th>\n      <th>stimuli_n_1</th>\n      <th>stimuli_n_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>2</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>851366.0</td>\n      <td>s.32ff642a-efe0-436f-8075-fa703d677fed.txt</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>867</td>\n      <td>2</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}